---
layout: post
title:  "Module 4. Outside Supervised Deep Learning"
date:   2024-07-13 12:45:23 +0900
categories: 공부
tags : [딥러닝,필기,공부]
---

조지아텍 온라인 석사과정 CS7647 '딥 러닝' Module 4 인트로 필기 내용

[전체 필기 링크 (구글독스)](https://docs.google.com/document/d/1_xd0n3O7GMBT9WNWLzyCKq7-PMLgz2GzvYObZuGAKfo/edit?usp=sharing)





<html>
<h3>
  <strong style="background-color: transparent; color: rgb(67, 67, 67);">Module 4. Outside Supervised Deep Learning</strong>
</h3>
<p>
  <br>
</p>
<p>
  <strong style="background-color: transparent; color: rgb(0, 0, 0);">0. Introduction</strong>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">0) 지금까지 배운 Supervised Deep learning 의 한계점</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">Data label을 필요로 하는데, Unlabeled data 수집이 훨씬 쉽다.&nbsp;</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">게임 플레이와 같이, 다양한 선택이 여러 단계에 걸쳐 이루어지며 마지막에 가서만 ‘승/패’의 라벨이 붙는 경우도 있다. 이런 상황들을 Sparse Supervision이라 한다.</span>
  </li>
</ul>
<p>
  <br>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">1) 머신러닝의 종류</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">지도학습 (Supervised Learning) :&nbsp;</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">인풋 : {X, Y)</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">학습 아웃풋 : f:X-&gt;Y, P(y|x)</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">예: 분류 등</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">비지도학습 (Unsupervised Learning)</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">인풋 : {X}</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">학습 아웃풋: P(x)</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">예: 클러스터링, 밀도추정(Density Estimation) 등</span>
  </li>
  <li class="ql-indent-2">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">참고로 이러한 클래식한 머신러닝 방법들은 feature learning을 활용하지 못함. 딥러닝을 효율적이게 하는 핵심요인이 feature space의 자동 최적화임. 어떻게 하면 Unsupervised Learning에서 feature space를 최적화할 수 있을까? 이번 모듈에서 배우게 됨.&nbsp;</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">강화학습 (Reinforcement Learning)</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">‘보상’의 개념으로 평가 피드백 제공</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">올바른 행동에 대한 supervision 없음</span>
  </li>
</ul>
<p>
  <br>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">2) Dealing with Low-labeled situations</span>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">라벨이 없거나 적은 상황을 아래와 같이 분류할 수 있음.&nbsp;</span>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">
    <img src="https://lh7-us.googleusercontent.com/docsz/AD_4nXceciM-kub81CjVrUsPAsOedVhSIwDNb5Z0eP7tGdmVavzL_uyLcS_cXYJUxHAuAPUMZZm_CH893NsDSvtJjlx1wPmevR-gfuxpDi9-UQVhtyOZJxS9TBx7cSQEU63cAnT0xzTIDFjwR5GbMlQgZOchfgM?key=80SjqRecUP0TcEWfrVrriw" height="538" width="1118">
  </span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">준지도학습 (Semi-Supervised) : 예를 들어, 1%의 라벨링된 데이터 (예: 이미지넷)과 99%의 라벨링 없는 데이터 (예: 라벨링 제거한 이미지넷)을 사용해 각각 지도학습/비지도학습으로 훈련시키는 것</span>
  </li>
  <li>
    <a href="https://paperswithcode.com/task/domain-adaptation" target="_blank" style="background-color: transparent; color: rgb(17, 85, 204);">Domain Adaptation</a>
    <span style="background-color: transparent; color: rgb(0, 0, 0);"> : 예를 들어, 그림으로 학습시키고 사진으로 테스트하는것. 즉 도메인이 shift되는데, 각 오브젝트의 의미 (예: 새 그림과 새 사진)은 동일하므로 Non-Semantic Shift임.&nbsp;</span>
  </li>
  <li>
    <a href="https://paperswithcode.com/task/domain-generalization" target="_blank" style="background-color: transparent; color: rgb(17, 85, 204);">Domain Generalization</a>
    <span style="background-color: transparent; color: rgb(0, 0, 0);"> : 다양한 도메인의 데이터로부터 학습하여, 어떤 도메인에도 적용 가능한 모델을 만들어 Unknown 도메인에 적용하는 것. 도메인에 Non-Semantic Shift가 있음.&nbsp;</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">Cross-Task Transfer : 라벨링 있는 데이터 소스로 학습시키고 라벨링 없는 타겟에 적용하는데, 소스와 타겟의 도메인이 다른것. 예를 들어 이미지넷으로 학습시키고 전혀 다른 분야의 사진 데이터셋에 적용. 즉 도메인에 Semantic Shift가 있음.&nbsp;</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">Few-Shot Learning : 타겟 데이터에는 카테고리당 라벨이 1개씩만 있는데, 대신 소스 데이터셋엔 카테고리가 방대한 것. 예를 들어 이미지넷으로 학습시키고 CIFAR10을 카테당 1개만 있도록 가공한 데이터셋에 적용함. 즉 도메인에 Semantic Shift가 있음.</span>
  </li>
  <li>
    <a href="https://sanghyu.tistory.com/184" target="_blank" style="background-color: transparent; color: rgb(17, 85, 204);">자기지도학습 (Un/Self-Supervised)</a>
    <span style="background-color: transparent; color: rgb(0, 0, 0);"> : 라벨 없이, 데이터셋에서 타겟으로 쓸만한 것을 스스로 파악해서 학습하는 것.&nbsp;</span>
  </li>
</ul>
<p>
  <br>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">3) Few-Shot Learning 자세히 보기</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">방대한 양의 Base class data와, 카테당 1-5개만 데이터가 있는 support set 및 query set을 사용.&nbsp;</span>
  </li>
</ul>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">
    <img src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcgQ459NiWjROOgmzNeT-edaF_W9J2CRKfkYFGq0hLMD1BrsXGPpbKeWX0sLe-7_aiAci7H099y0-ExPEKwRSNLySBMiDHnMusax8gzwdkhxRnYoZmkqTHm-OvRf1VEpE-RxL6cLd9qJqYNpVeQoRfl2SU?key=80SjqRecUP0TcEWfrVrriw" height="554" width="1101">
  </span>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">4) 준지도학습 (Semi-Supervised Learning) 자세히 보기</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">방대한 양의 라벨 없는 데이터와, 소량의 라벨 있는 데이터 사용.</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">효과있는 방법 : 소량의 라벨 데이터에 일반적 방식으로 훈련시키고, 라벨 없는 데이터에 대해 pseudo-label을 생성, confident한 항목들만 다시 학습데이터에 포함시키는 방법.&nbsp;</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">FixMatch : 여기에 augmented 데이터도 포함시킴. weak-augmented data로 pseudo-label을 만들고 이를 strongly-augmented data의 ground-truth로 사용.&nbsp;</span>
  </li>
</ul>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">
    <img src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcE1JEf-OlXrbXdymg_yXWCYB1JXy_dkWKQVh-FjJ3JF--MOdOZ2enF0ZKfB-BxaaSRjLWo6n8Z91BheIDweT7_NI72t1QRde4XPo2l0C_pJZmJl6_5NZcuSOtuAOlmoiF3eKk2jhUXOPlSmq7XgbhEPTQ?key=80SjqRecUP0TcEWfrVrriw" height="324" width="635">
  </span>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">5) 비지도학습 (Unsupervised Learning)</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">지도학습은 이산 데이터에 대해 ‘분류’, 연속 데이터에 대해 ‘회귀’ 사용.</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">비지도학습은 이산 데이터에 대해 ‘클러스터링’, 연속 데이터에 대해 ‘차원축소’를 사용. 또한 simplex에 대해 ‘밀도추정’을 사용. (x 에 대해 p(x)를 추정)</span>
  </li>
</ul>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">6) 오토인코더&nbsp;</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">차원축소 방식. 라벨 없이 feature representation 학습.&nbsp;</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">인코더-디코더 아키텍처로, 인코더에서 저차원으로 줄인뒤 이를 디코더가 인풋으로 받아서 고차원의 원래 인풋을 reproduce함. 인풋과 결과물 사이 오차를 MSE등의 손실함수로 최소화함.&nbsp;</span>
  </li>
</ul>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">7) Rotation Prediction&nbsp;</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">오토인코더를 일반화하여 여러 surrogate task에 적용할 수 있는데 그 중 하나. rotate된 이미지를 신경망에 입력하면 몇도 각도로 회전되었는지 출력하게 하는것. 치팅이 발생하지 않게 주의해야 함.&nbsp;</span>
  </li>
</ul>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">8) 생성형 모델</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">GAN (Generative Adversarial Networks) : 랜덤 벡터를 넣고 이를 통해 이미지를 생성. Discriminator에 이 이미지를 넣고 진짜인지 거짓인지 판별하게 함. Generator와 Discriminator에 각각 손실함수 적용. (게임이론 연관) 이를 통해 점점 실제같은 이미지를 생성하게 할 수 있음.&nbsp;</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">VAE (Variational Autoencoder)&nbsp;</span>
  </li>
</ul>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">9) 강화학습&nbsp;</span>
</p>
<ul>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">단계적 의사결정과 평가 피드백</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">Environment에 존재하는 Agent가 State를 참고하여 Action을 취함. 그 결과 Reward를 받음.</span>
  </li>
  <li class="ql-indent-1">
    <span style="background-color: transparent; color: rgb(0, 0, 0);">예시 : 게임하는 AI.&nbsp;&nbsp;</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">Agent는 Environment의 State를 Action에 매핑하기 위한 Policy를 학습해야 함.</span>
  </li>
  <li>
    <span style="background-color: transparent; color: rgb(0, 0, 0);">장기적으로 누적 reward를 최대화하도록 학습</span>
  </li>
</ul>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">&nbsp;</span>
</p>
<p>
  <span style="background-color: transparent; color: rgb(0, 0, 0);">결론 : 이번 모듈에선 여러 다른 방식의 ‘지도(Supervision)’에 대해 살펴볼 것임. 여기엔 라벨링 없는 데이터, 라벨링 있는/없는 데이터의 혼합, 그리고 보상 등이 해당됨.&nbsp;</span>
</p>
</html>